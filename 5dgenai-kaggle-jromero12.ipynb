{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-3-function-calling-with-the-gemini-api.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Gen AI Intensive Course Capstone 2025Q1**\n# **AI HealthDecode**\n# Juan Romero\nhttps://github.com/Jromero12/geanai_course_25","metadata":{"id":"b6e13eef3f5d"}},{"cell_type":"markdown","source":"## **Problem Definition** <a id='title1'></a>","metadata":{"execution":{"iopub.status.busy":"2025-04-17T15:08:35.915118Z","iopub.execute_input":"2025-04-17T15:08:35.916240Z","iopub.status.idle":"2025-04-17T15:08:35.920793Z","shell.execute_reply.started":"2025-04-17T15:08:35.916181Z","shell.execute_reply":"2025-04-17T15:08:35.919724Z"}}},{"cell_type":"markdown","source":"- Why is this problem important to solve?\n\nAdvances in medicine, nutrition, and technology have significantly increased life expectancy worldwide. However, our goal today isn’t simply to live longer—it’s to remain healthy, both physically and mentally, throughout those extra years. As populations age, future generations will inherit societies where older adults continue to contribute actively. This shift creates sustainability pressures on health‑care systems and pension schemes, but it also unlocks rich opportunities for intergenerational collaboration and innovation in health, work, and technology.\n\nPreventive health programs—including regular check‑ups and the use of personal data from wearables and wellness apps—empower individuals to spot risks early and adjust habits before chronic diseases develop.\n\nIn many Latin American and Caribbean (LAC) countries, lab results are still stored on paper or in fragmented, poorly managed digital systems. As a result, compiling a patient’s complete history often means tracking down records from multiple labs or printing stacks of reports—many of which get lost or become illegible. AI HealthDecode addresses these challenges by centralizing and translating laboratory data into clear, actionable insights, ensuring both patients and clinicians have seamless access to a patient’s full diagnostic history.\n\n","metadata":{"cellView":"form","id":"d6597b11df14","execution":{"iopub.status.busy":"2025-04-17T15:23:25.654591Z","iopub.execute_input":"2025-04-17T15:23:25.654977Z","iopub.status.idle":"2025-04-17T15:23:25.665780Z","shell.execute_reply.started":"2025-04-17T15:23:25.654946Z","shell.execute_reply":"2025-04-17T15:23:25.664441Z"}}},{"cell_type":"markdown","source":"### **The objective:** <a id='subtitle1_2'></a>","metadata":{}},{"cell_type":"markdown","source":"AI HealthDecode supports this workflow by harnessing the latest breakthroughs in generative AI. I’ve developed a Retrieval‑Augmented Generation (RAG) model to interpret laboratory test results with these core objectives:\n\n- **Bring Generative AI into Everyday Health:**\nAI HealthDecode isn’t just a backend engine—it lives at the point of care and in patients’ hands, delivering instant, conversational insights.\n\n- **Centralize & Annotate Lab Data in Plain Language:**\nRaw laboratory tables can be cryptic even for busy clinicians. AI HealthDecode aggregates every result into one unified repository and generates clear, jargon‑free explanations for non‑specialists.\n\n- **Empower Clinicians with Contextual Insights & Pattern Detection:**\nRather than replacing medical judgment, AI HealthDecode amplifies it—providing longitudinal trend charts, flagging outliers, and surfacing relevant guidelines so doctors can intervene earlier.\n\n- **Enable Patients & Foster a Preventive‑Health Mindset:**\nTrue transformation happens when patients own their health journey. AI HealthDecode translates data into actionable advice, delivers personalized reminders, and builds health literacy to sustain long‑term well‑being.\n\nBy weaving together human‑centric AI, transparent communication, clinician collaboration, and patient empowerment, AI HealthDecode drives earlier detection, sharper decision‑making, and ultimately longer, healthier lives.","metadata":{"execution":{"iopub.status.busy":"2025-04-17T15:50:47.605115Z","iopub.execute_input":"2025-04-17T15:50:47.605543Z","iopub.status.idle":"2025-04-17T15:50:47.614224Z","shell.execute_reply.started":"2025-04-17T15:50:47.605499Z","shell.execute_reply":"2025-04-17T15:50:47.612970Z"}}},{"cell_type":"markdown","source":"## **Setup**\n\nStart by installing and importing the Python SDK.","metadata":{"id":"ea197d1d464f"}},{"cell_type":"markdown","source":"## **Remove unused conflicting packages** ","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab \n!pip uninstall -qqy chromadb\n!pip uninstall -qqy langchain-community","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U -q \"google-genai==1.7.0\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\n# upgrade pip quietly\npip install --upgrade pip > /dev/null 2>&1\n\n# install both packages, discarding all stdout/stderr\npip install chromadb langchain-community > /dev/null 2>&1 || true","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install -U -q langchain-community","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!pip install ace_tools","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Import necessary libraries**","metadata":{}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import Markdown\nfrom google.api_core import retry\n\nfrom langchain.document_loaders import PyPDFLoader\nimport re\nimport pandas as pd\nfrom datetime import datetime\n\nimport chromadb\n\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\nfrom google.api_core import retry\n\nfrom google.genai import types\n\nfrom langchain.docstore.document import Document\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n\n\ngenai.__version__","metadata":{"id":"02bb0f551e25","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Set up API key**","metadata":{"id":"90e83cddff61"}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"id":"5cc8325f051d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Explore available models**\nI will be using the [`embedContent`](https://ai.google.dev/api/embeddings#method:-models.embedcontent) API method to calculate embeddings in this guide.","metadata":{}},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)\n\nfor m in client.models.list():\n    if \"embedContent\" in m.supported_actions:\n        print(m.name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Data**","metadata":{}},{"cell_type":"code","source":"%%bash\nfor file in lab_file1.pdf lab_file2.pdf lab_file3.pdf; do\n  wget -q \"https://raw.githubusercontent.com/Jromero12/geanai_course_25/main/$file\"\ndone","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pdf_paths = ['lab_file1.pdf', 'lab_file2.pdf', 'lab_file3.pdf']\nall_docs = [\n    doc\n    for path in pdf_paths\n    for doc in PyPDFLoader(path).load()\n]\nprint(f\"Loaded {len(all_docs)} pages total.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"records = []\n\nfor page in all_docs:\n    text = page.page_content\n\n    # 1. Flexible date regex: allows spaces between year digits\n    m = re.search(\n        r'FECHA\\s+DE\\s+REGISTRO\\s*[:\\s-]*'   # header\n        r'([0-3]?\\d)\\s*/\\s*'                 # day\n        r'([01]?\\d)\\s*/\\s*'                  # month\n        r'(\\d(?:\\s*\\d){3})',                 # year (4 digits, spaces allowed)\n        text,\n        flags=re.IGNORECASE\n    )\n    if m:\n        day_str, mon_str, year_str = m.group(1), m.group(2), m.group(3)\n        # remove any spaces in the captured year\n        year_str = re.sub(r'\\s+', '', year_str)  # \"202 3\" → \"2023\"\n        \n        # build a datetime\n        dt = datetime(\n            year=int(year_str),\n            month=int(mon_str),\n            day=int(day_str)\n        )\n        year_month = dt.strftime('%Y%m')    # e.g. \"202303\" or \"202504\"\n        day        = dt.strftime('%d')      # e.g. \"21\"\n    else:\n        year_month = day = None\n\n    # 2. Your existing lab‐test regex\n    pattern = re.findall(\n        r'(?P<test>[A-Z0-9 \\-\\(\\)]+)\\s+'\n        r'(?P<method>[\\w\\s\\-óÓéÉíÍúÚñÑ]+)?\\*?\\s+'\n        r'(?P<result>\\d+\\.?\\d*)\\s+'\n        r'(?P<units>\\w+\\s*/\\s*\\w+)\\s+'\n        r'(?P<range>[\\d\\.]+\\s*-\\s*[\\d\\.]+)',\n        text\n    )\n    if not pattern:\n        continue\n\n    # 3. Build DataFrame for this page, attach date parts\n    df_page = pd.DataFrame(\n        pattern,\n        columns=[\"Exam/Test\", \"Method\", \"Result\", \"Units\", \"Reference Range\"]\n    )\n    df_page[\"YearMonth\"] = year_month\n    df_page[\"Day\"]       = day\n\n    records.append(df_page)\n\n# 4. Concatenate and clean up as before\ndf = pd.concat(records, ignore_index=True)\ndf = df.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col)\ndf = df[\n    [\"YearMonth\", \"Day\", \"Exam/Test\", \"Method\", \"Result\", \"Units\", \"Reference Range\"]\n]\n\nprint(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Concatenate all rows into one string, with YearMonth and Day in their own columns\ntext_data = \"\\n\".join(\n    df.apply(\n        lambda row: (\n            f\"{row['YearMonth']} | {row['Day']} | \"\n            f\"{row['Exam/Test']} | {row['Method'] or ''} | \"\n            f\"{row['Result']} {row['Units']} | {row['Reference Range']}\"\n        ),\n        axis=1\n    )\n)\n\n# 2. Wrap as a single LangChain Document\ndata_filtrado = [Document(page_content=text_data)]\n\n# 3. Define and apply the text splitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=2500,\n    chunk_overlap=300,\n    length_function=len\n)\ndocuments = text_splitter.split_documents(data_filtrado)\n\n# 4. Output\nprint(f\"Generamos {len(documents)} fragmentos\")\nfor i, doc in enumerate(documents, start=1):\n    print(f\"\\n--- Fragmento {i} ---\\n{doc.page_content}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## **Creating the embedding database with ChromaDB**","metadata":{}},{"cell_type":"code","source":"# Define a retry policy. The model might make multiple consecutive calls automatically\n# for a complex query, this ensures the client retries if it hits quota limits.\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\nif not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n  genai.models.Models.generate_content = retry.Retry(\n      predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define a helper to retry when per-minute quota is reached.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    # Specify whether to generate embeddings for documents, or queries\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now create a [Chroma database client](https://docs.trychroma.com/getting-started) that uses the `GeminiEmbeddingFunction` and populate the database with the documents you defined above.","metadata":{}},{"cell_type":"code","source":"DB_NAME = \"googlecardb\"\n\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n\ndb.add(documents=[doc.page_content for doc in documents], ids=[str(i) for i in range(len(documents))])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Retrieval: Find relevant documents\n\nTo search the Chroma database, call the `query` method. Note that you also switch to the `retrieval_query` mode of embedding generation.","metadata":{"execution":{"iopub.status.busy":"2025-04-18T03:47:00.305849Z","iopub.execute_input":"2025-04-18T03:47:00.306448Z","iopub.status.idle":"2025-04-18T03:47:00.314701Z","shell.execute_reply.started":"2025-04-18T03:47:00.306382Z","shell.execute_reply":"2025-04-18T03:47:00.313213Z"}}},{"cell_type":"code","source":"# Switch to query mode when generating embeddings.\nembed_fn.document_mode = False\n\n# Search the Chroma DB using the specified query.\nquery = \"Can you give me an explanation of the test results? Compare the periods\"\n\nresult = db.query(query_texts=[query], n_results=5)\n[all_passages] = result[\"documents\"]\n\nquery_oneline = query.replace(\"\\n\", \" \")\n\nprompt = f\"\"\"\nYou are an assistant specialized in interpreting clinical lab results commonly requested by doctors. Your task is to help users understand these results clearly, especially if they have no background in health or medicine.\n\nExplain each concept using simple language, avoid technical jargon, and maintain a friendly and approachable tone. If any of the text is unrelated to the user’s question, feel free to ignore it.\n\nSince this assistant will be primarily used in Latin American countries, respond in Spanish, but also provide the explanation in English for those who may need it.\n\nAlways end with the following disclaimer:\nImportant: These are general recommendations only. It’s best to consult a doctor or a registered dietitian. They can provide a personalized treatment or nutrition plan based on your specific needs and medical history. Don’t hesitate to ask them if you have more questions!\n\nPREGUNTA: {query_oneline}\n\"\"\"\n\n\n# Add the retrieved documents to the prompt.\nfor passage in all_passages:\n    passage_oneline = passage.replace(\"\\n\", \" \")\n    prompt += f\"PASSAGE: {passage_oneline}\\n\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"answer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt)\n\nMarkdown(answer.text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Search the Chroma DB using the specified query.\nquery = \"Can you give me some dietary recommendations based on the latest analyzed results?\"\n\nresult = db.query(query_texts=[query], n_results=5)\n[all_passages] = result[\"documents\"]\n\nquery_oneline = query.replace(\"\\n\", \" \")\n\nprompt = f\"\"\"\nYou are an assistant specialized in interpreting clinical lab results commonly requested by doctors. Your task is to help users understand these results clearly, especially if they have no background in health or medicine.\n\nExplain each concept using simple language, avoid technical jargon, and maintain a friendly and approachable tone. If any of the text is unrelated to the user’s question, feel free to ignore it.\n\nSince this assistant will be primarily used in Latin American countries, respond in Spanish, but also provide the explanation in English for those who may need it.\n\nAlways end with the following disclaimer:\nImportant: These are general recommendations only. It’s best to consult a doctor or a registered dietitian. They can provide a personalized treatment or nutrition plan based on your specific needs and medical history. Don’t hesitate to ask them if you have more questions!\n\nPREGUNTA: {query_oneline}\n\"\"\"\n\n\n# Add the retrieved documents to the prompt.\nfor passage in all_passages:\n    passage_oneline = passage.replace(\"\\n\", \" \")\n    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n\nanswer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt)\n\nMarkdown(answer.text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Search the Chroma DB using the specified query.\nquery = \"Which specialist do you recommend I book to get a deeper interpretation of my analysis and guidance on the next steps?\"\n\nresult = db.query(query_texts=[query], n_results=5)\n[all_passages] = result[\"documents\"]\n\nquery_oneline = query.replace(\"\\n\", \" \")\n\nprompt = f\"\"\"You are an assistant specialized in interpreting clinical lab results commonly requested by doctors. Your task is to help users understand these results clearly, especially if they have no background in health or medicine.\n\nExplain each concept using simple language, avoid technical jargon, and maintain a friendly and approachable tone. If any of the text is unrelated to the user’s question, feel free to ignore it.\n\nSince this assistant will be primarily used in Latin American countries, respond in Spanish, but also provide the explanation in English for those who may need it.\n\nAlways end with the following disclaimer:\nImportant: These are general recommendations only. It’s best to consult a doctor or a registered dietitian. They can provide a personalized treatment or nutrition plan based on your specific needs and medical history. Don’t hesitate to ask them if you have more questions!\n\n\nPREGUNTA: {query_oneline}\n\"\"\"\n\n\n# Add the retrieved documents to the prompt.\nfor passage in all_passages:\n    passage_oneline = passage.replace(\"\\n\", \" \")\n    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n\nanswer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt)\n\nMarkdown(answer.text)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}